/// HTTP endpoint for querying site data
///
/// Provides a simple REST API for external tools (including Python analysis)
/// to query the current state of monitoring stations.
///
/// Endpoints:
/// - GET /site/{site_code} - Returns all relational data for a site
/// - GET /health - Service health check

use crate::analysis::groupings;
use crate::model::{GaugeReading};
use crate::stations::find_station;
use chrono::{DateTime, Utc};
use postgres::Client;
use serde::{Serialize, Deserialize};

// ---------------------------------------------------------------------------
// Response Types
// ---------------------------------------------------------------------------

/// Complete site data response including readings, thresholds, and metadata
#[derive(Debug, Serialize, Deserialize)]
pub struct SiteDataResponse {
    /// Site metadata
    pub site_code: String,
    pub site_name: String,
    pub description: String,
    pub latitude: f64,
    pub longitude: f64,
    
    /// Current readings (latest single point)
    pub current_discharge: Option<ReadingData>,
    pub current_stage: Option<ReadingData>,
    
    /// Recent time series (last 48 hours)
    pub recent_readings: RecentReadingsData,
    
    /// Flood thresholds (if defined)
    pub thresholds: Option<ThresholdData>,
    
    /// Monitoring state
    pub monitoring_state: Option<MonitoringStateData>,
    
    /// Historical flood events
    pub flood_events: Vec<FloodEventData>,
    
    /// Statistics from recent data
    pub statistics: Option<StatisticsData>,
    
    /// Data freshness
    pub last_updated: Option<DateTime<Utc>>,
    pub staleness_minutes: Option<i64>,
    
    /// Database record counts
    pub record_counts: RecordCountsData,
    
    /// CWMS data (Mississippi River for backwater analysis)
    pub cwms_context: Option<CwmsContextData>,
}

/// Recent time series readings (last 48 hours)
#[derive(Debug, Serialize, Deserialize)]
pub struct RecentReadingsData {
    pub discharge_readings: Vec<TimeSeriesPoint>,
    pub stage_readings: Vec<TimeSeriesPoint>,
    pub time_range_hours: f64,
    pub reading_count: usize,
}

/// Single time series point
#[derive(Debug, Serialize, Deserialize)]
pub struct TimeSeriesPoint {
    pub value: f64,
    pub datetime: String,
}

/// Historical flood event
#[derive(Debug, Serialize, Deserialize)]
pub struct FloodEventData {
    pub event_date: String,
    pub peak_stage_ft: Option<f64>,
    pub peak_discharge_cfs: Option<f64>,
    pub severity: Option<String>,
}

/// Statistics from recent data
#[derive(Debug, Serialize, Deserialize)]
pub struct StatisticsData {
    pub discharge_stats: Option<ParameterStats>,
    pub stage_stats: Option<ParameterStats>,
}

/// Statistics for a single parameter
#[derive(Debug, Serialize, Deserialize)]
pub struct ParameterStats {
    pub min: f64,
    pub max: f64,
    pub avg: f64,
    pub count: i64,
}

/// Record counts from various tables
#[derive(Debug, Serialize, Deserialize)]
pub struct RecordCountsData {
    pub total_readings: i64,
    pub discharge_readings: i64,
    pub stage_readings: i64,
    pub flood_events: i64,
}

/// CWMS context data (for backwater flood analysis)
#[derive(Debug, Serialize, Deserialize)]
pub struct CwmsContextData {
    pub mississippi_river_locations: Vec<CwmsLocationData>,
    pub illinois_river_locations: Vec<CwmsLocationData>,
    pub backwater_risk: Option<String>,
}

/// CWMS location with latest reading
#[derive(Debug, Serialize, Deserialize)]
pub struct CwmsLocationData {
    pub location_name: String,
    pub river_name: String,
    pub latest_stage_ft: Option<f64>,
    pub latest_timestamp: Option<String>,
    pub staleness_minutes: Option<i64>,
}

/// Simplified reading data for JSON response
#[derive(Debug, Serialize, Deserialize)]
pub struct ReadingData {
    pub value: f64,
    pub unit: String,
    pub datetime: String,
    pub qualifier: String,
}

/// Threshold data for JSON response
#[derive(Debug, Serialize, Deserialize)]
pub struct ThresholdData {
    pub action_stage_ft: f64,
    pub flood_stage_ft: f64,
    pub moderate_flood_stage_ft: f64,
    pub major_flood_stage_ft: f64,
}

/// Monitoring state for JSON response
#[derive(Debug, Serialize, Deserialize)]
pub struct MonitoringStateData {
    pub status: String,
    pub last_poll_attempted: Option<DateTime<Utc>>,
    pub last_poll_succeeded: Option<DateTime<Utc>>,
    pub consecutive_failures: i32,
    pub is_stale: bool,
}

// ---------------------------------------------------------------------------
// Data Fetching
// ---------------------------------------------------------------------------

/// Fetch all relational data for a site from the database
pub fn fetch_site_data(client: &mut Client, site_code: &str) -> Result<SiteDataResponse, String> {
    // Get station metadata from registry
    let station = find_station(site_code)
        .ok_or_else(|| format!("Site code {} not found in station registry", site_code))?;
    
    // Fetch latest readings from database (for current values)
    let readings = fetch_latest_readings(client, site_code)?;
    
    // Group readings by parameter
    let grouped = groupings::group_by_site(readings);
    let site_readings = grouped.get(site_code);
    
    // Extract current discharge and stage
    let current_discharge = site_readings
        .and_then(|sr| sr.discharge_cfs.as_ref())
        .map(reading_to_data);
    
    let current_stage = site_readings
        .and_then(|sr| sr.stage_ft.as_ref())
        .map(reading_to_data);
    
    // Fetch recent time series (last 48 hours)
    let recent_readings = fetch_recent_timeseries(client, site_code)?;
    
    // Fetch historical flood events
    let flood_events = fetch_flood_events(client, site_code)?;
    
    // Calculate statistics from recent data
    let statistics = calculate_statistics(client, site_code)?;
    
    // Fetch record counts
    let record_counts = fetch_record_counts(client, site_code)?;
    
    // Get monitoring state
    let monitoring_state = fetch_monitoring_state(client, site_code)?;
    
    // Calculate staleness
    let last_updated = site_readings
        .and_then(|sr| {
            sr.stage_ft.as_ref()
                .or(sr.discharge_cfs.as_ref())
                .and_then(|r| chrono::DateTime::parse_from_rfc3339(&r.datetime).ok())
                .map(|dt| dt.with_timezone(&Utc))
        });
    
    let staleness_minutes = last_updated.map(|dt| (Utc::now() - dt).num_minutes());
    
    // Convert thresholds
    let thresholds = station.thresholds.as_ref().map(|t| ThresholdData {
        action_stage_ft: t.action_stage_ft,
        flood_stage_ft: t.flood_stage_ft,
        moderate_flood_stage_ft: t.moderate_flood_stage_ft,
        major_flood_stage_ft: t.major_flood_stage_ft,
    });
    
    // Fetch CWMS context data (Mississippi River levels for backwater analysis)
    let cwms_context = fetch_cwms_context(client).ok();
    
    Ok(SiteDataResponse {
        site_code: station.site_code.clone(),
        site_name: station.name.clone(),
        description: station.description.clone(),
        latitude: station.latitude,
        longitude: station.longitude,
        current_discharge,
        current_stage,
        recent_readings,
        thresholds,
        monitoring_state,
        flood_events,
        statistics,
        last_updated,
        staleness_minutes,
        record_counts,
        cwms_context,
    })
}

/// Fetch latest readings for a site from the database
fn fetch_latest_readings(client: &mut Client, site_code: &str) -> Result<Vec<GaugeReading>, String> {
    let rows = client.query(
        "SELECT DISTINCT ON (parameter_code)
            site_code,
            parameter_code,
            unit,
            value,
            reading_time,
            qualifier
         FROM usgs_raw.gauge_readings
         WHERE site_code = $1
         ORDER BY parameter_code, reading_time DESC",
        &[&site_code]
    ).map_err(|e| format!("Database query failed: {}", e))?;
    
    let mut readings = Vec::new();
    
    for row in rows {
        let site_code: String = row.get(0);
        let parameter_code: String = row.get(1);
        let unit: String = row.get(2);
        let value: rust_decimal::Decimal = row.get(3);
        let reading_time: DateTime<Utc> = row.get(4);
        let qualifier: String = row.get(5);
        
        // Find site name from registry
        let site_name = find_station(&site_code)
            .map(|s| s.name.clone())
            .unwrap_or_else(|| site_code.clone());
        
        readings.push(GaugeReading {
            site_code,
            site_name,
            parameter_code,
            unit,
            value: value.to_string().parse().unwrap_or(0.0),
            datetime: reading_time.to_rfc3339(),
            qualifier,
        });
    }
    
    Ok(readings)
}

/// Fetch monitoring state for a site
fn fetch_monitoring_state(client: &mut Client, site_code: &str) -> Result<Option<MonitoringStateData>, String> {
    let rows = client.query(
        "SELECT status, last_poll_attempted, last_poll_succeeded, consecutive_failures, is_stale
         FROM usgs_raw.monitoring_state
         WHERE site_code = $1",
        &[&site_code]
    ).map_err(|e| format!("Failed to fetch monitoring state: {}", e))?;
    
    if rows.is_empty() {
        return Ok(None);
    }
    
    let row = &rows[0];
    Ok(Some(MonitoringStateData {
        status: row.get(0),
        last_poll_attempted: row.get(1),
        last_poll_succeeded: row.get(2),
        consecutive_failures: row.get(3),
        is_stale: row.get(4),
    }))
}

/// Fetch recent time series data (last 48 hours)
fn fetch_recent_timeseries(client: &mut Client, site_code: &str) -> Result<RecentReadingsData, String> {
    let rows = client.query(
        "SELECT parameter_code, value, reading_time
         FROM usgs_raw.gauge_readings
         WHERE site_code = $1
           AND reading_time >= NOW() - INTERVAL '48 hours'
         ORDER BY reading_time DESC
         LIMIT 1000",
        &[&site_code]
    ).map_err(|e| format!("Failed to fetch recent readings: {}", e))?;
    
    let mut discharge_readings = Vec::new();
    let mut stage_readings = Vec::new();
    
    for row in rows {
        let parameter_code: String = row.get(0);
        let value: rust_decimal::Decimal = row.get(1);
        let reading_time: DateTime<Utc> = row.get(2);
        
        let point = TimeSeriesPoint {
            value: value.to_string().parse().unwrap_or(0.0),
            datetime: reading_time.to_rfc3339(),
        };
        
        match parameter_code.as_str() {
            "00060" => discharge_readings.push(point),
            "00065" => stage_readings.push(point),
            _ => {}
        }
    }
    
    let reading_count = discharge_readings.len() + stage_readings.len();
    
    Ok(RecentReadingsData {
        discharge_readings,
        stage_readings,
        time_range_hours: 48.0,
        reading_count,
    })
}

/// Fetch historical flood events
fn fetch_flood_events(client: &mut Client, site_code: &str) -> Result<Vec<FloodEventData>, String> {
    let rows = match client.query(
        "SELECT event_date, peak_stage_ft, peak_discharge_cfs, severity
         FROM nws.flood_events
         WHERE site_code = $1
         ORDER BY event_date DESC
         LIMIT 50",
        &[&site_code]
    ) {
        Ok(rows) => rows,
        Err(e) => {
            // Table might not exist yet, return empty vec
            eprintln!("Note: Could not fetch flood events: {}", e);
            return Ok(Vec::new());
        }
    };
    
    let mut events = Vec::new();
    for row in rows {
        let event_date: chrono::NaiveDate = row.get(0);
        events.push(FloodEventData {
            event_date: event_date.to_string(),
            peak_stage_ft: row.get(1),
            peak_discharge_cfs: row.get(2),
            severity: row.get(3),
        });
    }
    
    Ok(events)
}

/// Calculate statistics from recent data (last 7 days)
fn calculate_statistics(client: &mut Client, site_code: &str) -> Result<Option<StatisticsData>, String> {
    // Discharge stats
    let discharge_rows = client.query(
        "SELECT MIN(value), MAX(value), AVG(value), COUNT(*)
         FROM usgs_raw.gauge_readings
         WHERE site_code = $1
           AND parameter_code = '00060'
           AND reading_time >= NOW() - INTERVAL '7 days'",
        &[&site_code]
    ).map_err(|e| format!("Failed to calculate discharge stats: {}", e))?;
    
    let discharge_stats = if !discharge_rows.is_empty() {
        let row = &discharge_rows[0];
        let min: Option<rust_decimal::Decimal> = row.get(0);
        let max: Option<rust_decimal::Decimal> = row.get(1);
        let avg: Option<rust_decimal::Decimal> = row.get(2);
        let count: i64 = row.get(3);
        
        if count > 0 && min.is_some() {
            Some(ParameterStats {
                min: min.unwrap().to_string().parse().unwrap_or(0.0),
                max: max.unwrap().to_string().parse().unwrap_or(0.0),
                avg: avg.unwrap().to_string().parse().unwrap_or(0.0),
                count,
            })
        } else {
            None
        }
    } else {
        None
    };
    
    // Stage stats
    let stage_rows = client.query(
        "SELECT MIN(value), MAX(value), AVG(value), COUNT(*)
         FROM usgs_raw.gauge_readings
         WHERE site_code = $1
           AND parameter_code = '00065'
           AND reading_time >= NOW() - INTERVAL '7 days'",
        &[&site_code]
    ).map_err(|e| format!("Failed to calculate stage stats: {}", e))?;
    
    let stage_stats = if !stage_rows.is_empty() {
        let row = &stage_rows[0];
        let min: Option<rust_decimal::Decimal> = row.get(0);
        let max: Option<rust_decimal::Decimal> = row.get(1);
        let avg: Option<rust_decimal::Decimal> = row.get(2);
        let count: i64 = row.get(3);
        
        if count > 0 && min.is_some() {
            Some(ParameterStats {
                min: min.unwrap().to_string().parse().unwrap_or(0.0),
                max: max.unwrap().to_string().parse().unwrap_or(0.0),
                avg: avg.unwrap().to_string().parse().unwrap_or(0.0),
                count,
            })
        } else {
            None
        }
    } else {
        None
    };
    
    if discharge_stats.is_some() || stage_stats.is_some() {
        Ok(Some(StatisticsData {
            discharge_stats,
            stage_stats,
        }))
    } else {
        Ok(None)
    }
}

/// Fetch record counts from database
fn fetch_record_counts(client: &mut Client, site_code: &str) -> Result<RecordCountsData, String> {
    // Total readings
    let total_rows = client.query(
        "SELECT COUNT(*) FROM usgs_raw.gauge_readings WHERE site_code = $1",
        &[&site_code]
    ).map_err(|e| format!("Failed to count total readings: {}", e))?;
    let total_readings: i64 = total_rows[0].get(0);
    
    // Discharge readings
    let discharge_rows = client.query(
        "SELECT COUNT(*) FROM usgs_raw.gauge_readings WHERE site_code = $1 AND parameter_code = '00060'",
        &[&site_code]
    ).map_err(|e| format!("Failed to count discharge readings: {}", e))?;
    let discharge_readings: i64 = discharge_rows[0].get(0);
    
    // Stage readings
    let stage_rows = client.query(
        "SELECT COUNT(*) FROM usgs_raw.gauge_readings WHERE site_code = $1 AND parameter_code = '00065'",
        &[&site_code]
    ).map_err(|e| format!("Failed to count stage readings: {}", e))?;
    let stage_readings: i64 = stage_rows[0].get(0);
    
    // Flood events (may fail if table doesn't exist)
    let flood_events = client.query(
        "SELECT COUNT(*) FROM nws.flood_events WHERE site_code = $1",
        &[&site_code]
    ).unwrap_or_else(|_| vec![])
        .first()
        .and_then(|row| row.get::<_, Option<i64>>(0))
        .unwrap_or(0);
    
    Ok(RecordCountsData {
        total_readings,
        discharge_readings,
        stage_readings,
        flood_events,
    })
}

/// Convert GaugeReading to ReadingData
fn reading_to_data(reading: &GaugeReading) -> ReadingData {
    ReadingData {
        value: reading.value,
        unit: reading.unit.clone(),
        datetime: reading.datetime.clone(),
        qualifier: reading.qualifier.clone(),
    }
}

// ---------------------------------------------------------------------------
// HTTP Server
// ---------------------------------------------------------------------------

/// Start HTTP endpoint server on the specified port
pub fn start_endpoint_server(port: u16, mut client: Client) -> Result<(), String> {
    let server = tiny_http::Server::http(format!("0.0.0.0:{}", port))
        .map_err(|e| format!("Failed to start HTTP server: {}", e))?;
    
    println!("ðŸ“¡ HTTP endpoint listening on http://0.0.0.0:{}", port);
    println!("   GET /site/{{site_code}} - Query site data");
    println!("   GET /health - Service health check\n");
    
    for request in server.incoming_requests() {
        let url = request.url();
        
        // Route requests
        let response = if url == "/health" {
            handle_health()
        } else if url.starts_with("/site/") {
            let site_code = url.trim_start_matches("/site/");
            handle_site_query(&mut client, site_code)
        } else {
            create_response(
                404,
                serde_json::json!({
                    "error": "Not found",
                    "available_endpoints": ["/health", "/site/{site_code}"]
                })
            )
        };
        
        if let Err(e) = request.respond(response) {
            eprintln!("Failed to send response: {}", e);
        }
    }
    
    Ok(())
}

/// Handle /health endpoint
fn handle_health() -> tiny_http::Response<std::io::Cursor<Vec<u8>>> {
    create_response(
        200,
        serde_json::json!({
            "status": "ok",
            "service": "flomon_service",
            "version": "0.1.0"
        })
    )
}

/// Handle /site/{site_code} endpoint
fn handle_site_query(client: &mut Client, site_code: &str) -> tiny_http::Response<std::io::Cursor<Vec<u8>>> {
    match fetch_site_data(client, site_code) {
        Ok(data) => {
            create_response(200, serde_json::to_value(&data).unwrap())
        }
        Err(e) => {
            create_response(
                404,
                serde_json::json!({
                    "error": e,
                    "site_code": site_code
                })
            )
        }
    }
}

/// Create HTTP response with JSON body
fn create_response(status_code: u16, json: serde_json::Value) -> tiny_http::Response<std::io::Cursor<Vec<u8>>> {
    let body = serde_json::to_string_pretty(&json).unwrap();
    let bytes = body.into_bytes();
    
    tiny_http::Response::from_data(bytes)
        .with_status_code(tiny_http::StatusCode::from(status_code))
        .with_header(
            tiny_http::Header::from_bytes(&b"Content-Type"[..], &b"application/json"[..]).unwrap()
        )
}

/// Fetch CWMS context data (Mississippi River levels for backwater analysis)
fn fetch_cwms_context(client: &mut Client) -> Result<CwmsContextData, String> {
    let rows = client.query(
        "SELECT 
            l.location_name,
            l.river_name,
            (SELECT t.value 
             FROM usace.cwms_timeseries t 
             WHERE t.location_id = l.location_id 
             ORDER BY t.timestamp DESC 
             LIMIT 1) as latest_value,
            (SELECT t.timestamp 
             FROM usace.cwms_timeseries t 
             WHERE t.location_id = l.location_id 
             ORDER BY t.timestamp DESC 
             LIMIT 1) as latest_timestamp
         FROM usace.cwms_locations l
         WHERE l.monitored = true
         ORDER BY l.river_name, l.location_name",
        &[]
    ).map_err(|e| format!("CWMS query failed: {}", e))?;
    
    let mut mississippi_locations = Vec::new();
    let mut illinois_locations = Vec::new();
    
    for row in rows {
        let location_name: String = row.get(0);
        let river_name: String = row.get(1);
        let latest_value: Option<rust_decimal::Decimal> = row.get(2);
        let latest_timestamp: Option<DateTime<Utc>> = row.get(3);
        
        let latest_stage_ft = latest_value.map(|v| v.to_string().parse().unwrap_or(0.0));
        let staleness_minutes = latest_timestamp.map(|ts| (Utc::now() - ts).num_minutes());
        
        let location_data = CwmsLocationData {
            location_name: location_name.clone(),
            river_name: river_name.clone(),
            latest_stage_ft,
            latest_timestamp: latest_timestamp.map(|ts| ts.to_rfc3339()),
            staleness_minutes,
        };
        
        if river_name.contains("Mississippi") {
            mississippi_locations.push(location_data);
        } else if river_name.contains("Illinois") {
            illinois_locations.push(location_data);
        }
    }
    
    Ok(CwmsContextData {
        mississippi_river_locations: mississippi_locations,
        illinois_river_locations: illinois_locations,
        backwater_risk: None, // TODO: Calculate based on Mississippi River elevations
    })
}

// ---------------------------------------------------------------------------
// Tests
// ---------------------------------------------------------------------------

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_reading_to_data_conversion() {
        let reading = GaugeReading {
            site_code: "05568500".to_string(),
            site_name: "Kingston Mines".to_string(),
            parameter_code: "00065".to_string(),
            unit: "ft".to_string(),
            value: 15.5,
            datetime: "2024-05-01T12:00:00.000-05:00".to_string(),
            qualifier: "P".to_string(),
        };
        
        let data = reading_to_data(&reading);
        
        assert_eq!(data.value, 15.5);
        assert_eq!(data.unit, "ft");
        assert_eq!(data.qualifier, "P");
    }
}
